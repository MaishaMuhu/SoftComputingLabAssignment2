{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "170104017_exp_02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hen4ojHzI1O"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.autograd import Variable\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "from os import path\n",
        "import shutil"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_4G6XUSzLt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62a0b75b-4e1d-4f70-b00d-8d74ebebd410"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "url = '/content/drive/MyDrive/SoftComputingLab/ASS_2/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mILHAHnczPlL"
      },
      "source": [
        "dataset_C = url + 'Dataset C.zip'\n",
        "with ZipFile(dataset_C, 'r') as zip:\n",
        "  zip.extractall()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "DoQew-ifP_oO",
        "outputId": "4a39c4a4-5b68-4200-842c-1f4fb074274f"
      },
      "source": [
        "PATH = '/content/'\n",
        "data_labels = pd.read_csv(PATH + 'training-c.csv', usecols = ['filename', 'digit'])\n",
        "print(data_labels.shape)\n",
        "data_labels.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24298, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c00000.png</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c00001.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c00002.png</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c00003.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c00004.png</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     filename  digit\n",
              "0  c00000.png      6\n",
              "1  c00001.png      1\n",
              "2  c00002.png      3\n",
              "3  c00003.png      2\n",
              "4  c00004.png      7"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhs9ACb1zS47"
      },
      "source": [
        "TRAIN_PATH = url + 'Exp2'\n",
        "os.mkdir(TRAIN_PATH)\n",
        "\n",
        "def processImages(folder_name):\n",
        "  src = PATH + folder_name + '/'\n",
        "  dir_folders = os.listdir(src)\n",
        "  for dir_name in dir_folders:\n",
        "    file_name = os.path.join(src, dir_name)\n",
        "    if os.path.isfile(file_name):\n",
        "      shutil.copy(file_name, TRAIN_PATH) \n",
        "\n",
        "processImages('training-c')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4l1Divk0nLy"
      },
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, df, root, transform=None):\n",
        "        self.data = df\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        item = self.data.iloc[index]\n",
        "        \n",
        "        path = self.root + \"/\" + item[0]\n",
        "        image = Image.open(path).convert('L')\n",
        "        label = item[1]\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        return image, label"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRegpB521eKq",
        "outputId": "f1058694-915b-4c3d-fb4b-1dbb2c9a13d9"
      },
      "source": [
        "mean = [0.5,]\n",
        "std = [0.5, ]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(28),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize(28),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "train_data  = Dataset(data_labels, TRAIN_PATH, train_transform)\n",
        "test_data = Dataset(data_labels, TRAIN_PATH, test_transform)\n",
        "\n",
        "print(\"Trainig Samples: \", len(train_data))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainig Samples:  24298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIWasz2YAMGr"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb_b9B6EAYmP"
      },
      "source": [
        "# **Experiment 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBKzg1IpAko9",
        "outputId": "5d408198-b536-46d7-8659-f4c6d747bc40"
      },
      "source": [
        "#Batch Parameters\n",
        "batch_size = 250\n",
        "num_iters = 20000\n",
        "input_dim = 28*28\n",
        "num_hidden = 200\n",
        "output_dim = 10\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "num_epochs = num_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "print(num_epochs)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zAeuK55CH8t",
        "outputId": "9101d4be-cb50-4643-ca68-120e59b5ef4e"
      },
      "source": [
        "test_size = 0.2\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(test_size * num_train))\n",
        "train_idx, test_idx = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=batch_size,\n",
        "    sampler=test_sampler)\n",
        "\n",
        "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
        "print(\"Test dataloader:{}\".format(len(test_loader)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader:78\n",
            "Test dataloader:20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8W9e4T1CJ6F"
      },
      "source": [
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "\n",
        "       #First Hidden Layer\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        self.relu_1 = nn.ReLU()\n",
        "\n",
        "        #2nd Hidden Layer\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_2 = nn.ReLU()\n",
        "\n",
        "         #3rd Hidden Layer\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_3 = nn.Softmax(dim=0)\n",
        "\n",
        "         #4th Hidden Layer\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_4 = nn.Softmax(dim=0)\n",
        "\n",
        "         #5th Hidden Layer\n",
        "        self.linear_5= nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_5= nn.Tanh()\n",
        "        \n",
        "        #6th Hidden Layer\n",
        "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_6 = nn.Tanh()\n",
        "\n",
        "        #7th Hidden Layer\n",
        "        self.linear_7 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_7 = nn.Tanh()\n",
        "\n",
        " \n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        " \n",
        "    def forward(self, x):\n",
        "        out  = self.linear_1(x)\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        out  = self.linear_2(out)\n",
        "        out = self.relu_2(out)\n",
        " \n",
        "        out  = self.linear_3(out)\n",
        "        out = self.relu_3(out)\n",
        " \n",
        "        out  = self.linear_4(out)\n",
        "        out = self.relu_4(out)\n",
        " \n",
        "        out  = self.linear_5(out)\n",
        "        out = self.relu_5(out)\n",
        " \n",
        "        out  = self.linear_6(out)\n",
        "        out = self.relu_6(out)\n",
        "\n",
        "        out  = self.linear_7(out)\n",
        "        out = self.relu_7(out)\n",
        "\n",
        "        \n",
        "        \n",
        "        probas  = self.linear_out(out)\n",
        "        return probas"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZn9wJWrTmkE",
        "outputId": "f9eded91-c159-471a-df7f-3d98a35a659c"
      },
      "source": [
        "model = DeepNeuralNetworkModel(input_size = input_dim, num_classes = output_dim, num_hidden = num_hidden)\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepNeuralNetworkModel(\n",
              "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
              "  (relu_1): ReLU()\n",
              "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_2): ReLU()\n",
              "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_3): Softmax(dim=0)\n",
              "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_4): Softmax(dim=0)\n",
              "  (linear_5): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_5): Tanh()\n",
              "  (linear_6): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_6): Tanh()\n",
              "  (linear_7): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_7): Tanh()\n",
              "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAPcDAJtT5-Q"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3JQLXFgT7iq",
        "outputId": "f93d5fa4-f793-4458-bec4-a893442bbb39"
      },
      "source": [
        "iteration_loss = []\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch: ', epoch + 1)\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images) \n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:        \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 28*28).to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                total += labels.size(0)\n",
        "\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "\n",
        "            iteration_loss.append(loss.item())\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1\n",
            "Epoch:  2\n",
            "Epoch:  3\n",
            "Epoch:  4\n",
            "Epoch:  5\n",
            "Epoch:  6\n",
            "Epoch:  7\n",
            "Iteration: 500. Loss: 1.5876516103744507. Accuracy: 39.823008849557525\n",
            "Epoch:  8\n",
            "Epoch:  9\n",
            "Epoch:  10\n",
            "Epoch:  11\n",
            "Epoch:  12\n",
            "Epoch:  13\n",
            "Iteration: 1000. Loss: 1.4033628702163696. Accuracy: 45.8736365507306\n",
            "Epoch:  14\n",
            "Epoch:  15\n",
            "Epoch:  16\n",
            "Epoch:  17\n",
            "Epoch:  18\n",
            "Epoch:  19\n",
            "Epoch:  20\n",
            "Iteration: 1500. Loss: 1.2620534896850586. Accuracy: 47.540646223502776\n",
            "Epoch:  21\n",
            "Epoch:  22\n",
            "Epoch:  23\n",
            "Epoch:  24\n",
            "Epoch:  25\n",
            "Epoch:  26\n",
            "Iteration: 2000. Loss: 1.2925591468811035. Accuracy: 46.94381559991768\n",
            "Epoch:  27\n",
            "Epoch:  28\n",
            "Epoch:  29\n",
            "Epoch:  30\n",
            "Epoch:  31\n",
            "Epoch:  32\n",
            "Epoch:  33\n",
            "Iteration: 2500. Loss: 1.2613424062728882. Accuracy: 48.137476847087875\n",
            "Epoch:  34\n",
            "Epoch:  35\n",
            "Epoch:  36\n",
            "Epoch:  37\n",
            "Epoch:  38\n",
            "Epoch:  39\n",
            "Iteration: 3000. Loss: 1.1950424909591675. Accuracy: 47.664128421485906\n",
            "Epoch:  40\n",
            "Epoch:  41\n",
            "Epoch:  42\n",
            "Epoch:  43\n",
            "Epoch:  44\n",
            "Epoch:  45\n",
            "Iteration: 3500. Loss: 1.2351393699645996. Accuracy: 50.03087054949578\n",
            "Epoch:  46\n",
            "Epoch:  47\n",
            "Epoch:  48\n",
            "Epoch:  49\n",
            "Epoch:  50\n",
            "Epoch:  51\n",
            "Epoch:  52\n",
            "Iteration: 4000. Loss: 1.1135808229446411. Accuracy: 49.41345955958016\n",
            "Epoch:  53\n",
            "Epoch:  54\n",
            "Epoch:  55\n",
            "Epoch:  56\n",
            "Epoch:  57\n",
            "Epoch:  58\n",
            "Iteration: 4500. Loss: 1.0907399654388428. Accuracy: 50.29841531179255\n",
            "Epoch:  59\n",
            "Epoch:  60\n",
            "Epoch:  61\n",
            "Epoch:  62\n",
            "Epoch:  63\n",
            "Epoch:  64\n",
            "Epoch:  65\n",
            "Iteration: 5000. Loss: 1.1688090562820435. Accuracy: 51.45091582630171\n",
            "Epoch:  66\n",
            "Epoch:  67\n",
            "Epoch:  68\n",
            "Epoch:  69\n",
            "Epoch:  70\n",
            "Epoch:  71\n",
            "Iteration: 5500. Loss: 1.060933232307434. Accuracy: 52.76805927145503\n",
            "Epoch:  72\n",
            "Epoch:  73\n",
            "Epoch:  74\n",
            "Epoch:  75\n",
            "Epoch:  76\n",
            "Epoch:  77\n",
            "Iteration: 6000. Loss: 1.182711124420166. Accuracy: 51.40975509364067\n",
            "Epoch:  78\n",
            "Epoch:  79\n",
            "Epoch:  80\n",
            "Epoch:  81\n",
            "Epoch:  82\n",
            "Epoch:  83\n",
            "Epoch:  84\n",
            "Iteration: 6500. Loss: 0.9979344606399536. Accuracy: 51.63613912327639\n",
            "Epoch:  85\n",
            "Epoch:  86\n",
            "Epoch:  87\n",
            "Epoch:  88\n",
            "Epoch:  89\n",
            "Epoch:  90\n",
            "Iteration: 7000. Loss: 1.2142971754074097. Accuracy: 51.677299855937434\n",
            "Epoch:  91\n",
            "Epoch:  92\n",
            "Epoch:  93\n",
            "Epoch:  94\n",
            "Epoch:  95\n",
            "Epoch:  96\n",
            "Epoch:  97\n",
            "Iteration: 7500. Loss: 1.1841840744018555. Accuracy: 51.80078205392056\n",
            "Epoch:  98\n",
            "Epoch:  99\n",
            "Epoch:  100\n",
            "Epoch:  101\n",
            "Epoch:  102\n",
            "Epoch:  103\n",
            "Iteration: 8000. Loss: 1.107827067375183. Accuracy: 52.25355011319201\n",
            "Epoch:  104\n",
            "Epoch:  105\n",
            "Epoch:  106\n",
            "Epoch:  107\n",
            "Epoch:  108\n",
            "Epoch:  109\n",
            "Iteration: 8500. Loss: 1.0421497821807861. Accuracy: 54.27042601358304\n",
            "Epoch:  110\n",
            "Epoch:  111\n",
            "Epoch:  112\n",
            "Epoch:  113\n",
            "Epoch:  114\n",
            "Epoch:  115\n",
            "Epoch:  116\n",
            "Iteration: 9000. Loss: 1.109074592590332. Accuracy: 53.55011319201482\n",
            "Epoch:  117\n",
            "Epoch:  118\n",
            "Epoch:  119\n",
            "Epoch:  120\n",
            "Epoch:  121\n",
            "Epoch:  122\n",
            "Iteration: 9500. Loss: 0.9632962942123413. Accuracy: 52.27413047952253\n",
            "Epoch:  123\n",
            "Epoch:  124\n",
            "Epoch:  125\n",
            "Epoch:  126\n",
            "Epoch:  127\n",
            "Epoch:  128\n",
            "Epoch:  129\n",
            "Iteration: 10000. Loss: 1.0751307010650635. Accuracy: 53.138505865404404\n",
            "Epoch:  130\n",
            "Epoch:  131\n",
            "Epoch:  132\n",
            "Epoch:  133\n",
            "Epoch:  134\n",
            "Epoch:  135\n",
            "Iteration: 10500. Loss: 0.9740250706672668. Accuracy: 53.69417575632846\n",
            "Epoch:  136\n",
            "Epoch:  137\n",
            "Epoch:  138\n",
            "Epoch:  139\n",
            "Epoch:  140\n",
            "Epoch:  141\n",
            "Epoch:  142\n",
            "Iteration: 11000. Loss: 0.9822185039520264. Accuracy: 54.18810454826096\n",
            "Epoch:  143\n",
            "Epoch:  144\n",
            "Epoch:  145\n",
            "Epoch:  146\n",
            "Epoch:  147\n",
            "Epoch:  148\n",
            "Iteration: 11500. Loss: 0.9355905652046204. Accuracy: 53.92055978596419\n",
            "Epoch:  149\n",
            "Epoch:  150\n",
            "Epoch:  151\n",
            "Epoch:  152\n",
            "Epoch:  153\n",
            "Epoch:  154\n",
            "Iteration: 12000. Loss: 1.056005597114563. Accuracy: 55.5258283597448\n",
            "Epoch:  155\n",
            "Epoch:  156\n",
            "Epoch:  157\n",
            "Epoch:  158\n",
            "Epoch:  159\n",
            "Epoch:  160\n",
            "Epoch:  161\n",
            "Iteration: 12500. Loss: 0.9662630558013916. Accuracy: 53.89997941963367\n",
            "Epoch:  162\n",
            "Epoch:  163\n",
            "Epoch:  164\n",
            "Epoch:  165\n",
            "Epoch:  166\n",
            "Epoch:  167\n",
            "Iteration: 13000. Loss: 1.0930724143981934. Accuracy: 53.57069355834534\n",
            "Epoch:  168\n",
            "Epoch:  169\n",
            "Epoch:  170\n",
            "Epoch:  171\n",
            "Epoch:  172\n",
            "Epoch:  173\n",
            "Epoch:  174\n",
            "Iteration: 13500. Loss: 0.953643798828125. Accuracy: 53.67359538999794\n",
            "Epoch:  175\n",
            "Epoch:  176\n",
            "Epoch:  177\n",
            "Epoch:  178\n",
            "Epoch:  179\n",
            "Epoch:  180\n",
            "Iteration: 14000. Loss: 1.0048186779022217. Accuracy: 54.31158674624408\n",
            "Epoch:  181\n",
            "Epoch:  182\n",
            "Epoch:  183\n",
            "Epoch:  184\n",
            "Epoch:  185\n",
            "Epoch:  186\n",
            "Iteration: 14500. Loss: 0.9840937256813049. Accuracy: 53.755916855320024\n",
            "Epoch:  187\n",
            "Epoch:  188\n",
            "Epoch:  189\n",
            "Epoch:  190\n",
            "Epoch:  191\n",
            "Epoch:  192\n",
            "Epoch:  193\n",
            "Iteration: 15000. Loss: 1.1011638641357422. Accuracy: 54.558551142210334\n",
            "Epoch:  194\n",
            "Epoch:  195\n",
            "Epoch:  196\n",
            "Epoch:  197\n",
            "Epoch:  198\n",
            "Epoch:  199\n",
            "Iteration: 15500. Loss: 0.8855723738670349. Accuracy: 55.09364066680387\n",
            "Epoch:  200\n",
            "Epoch:  201\n",
            "Epoch:  202\n",
            "Epoch:  203\n",
            "Epoch:  204\n",
            "Epoch:  205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVLskgHZUFTX"
      },
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/SoftComputingLab/ASS_2/model_base1.pkl')"
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}